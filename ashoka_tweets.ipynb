{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2349143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jijas\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87e3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\jijas\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from tweepy) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from requests<3,>=2.11.1->tweepy) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1193227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jijas\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: textblob in c:\\users\\jijas\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jijas\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "import sys\n",
    "!{sys.executable} -m pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31fea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342c18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(\"wvID4HbxNGrL9gEn7HtyaqY98\", \"CBbRMJSTQvNRJHASjvHI5Vmm0bvoku8nhIbMyqJP0XfQQilQTZ\")\n",
    "consumer_key = \"t6nkbhDcmFMc7aHFLi70TX0k7\"\n",
    "consumer_secret = \"E2fHiqfgx2BAba2tbwKOSnvvIsPZatHMgqujkbEgCfTgvcjc7d\"\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHo%2BWwEAAAAAdMKyzHW7qRYwmwBmSfAXUglk6%2Bw%3DVH9D2JBGD2QfVqxOIk5yuPyV3JgRb3Xe5FKwl7B0PRQi5KqpLI\"\n",
    "access_token = \"1469208266198732803-REOnVL3cmm7hBcvfPTAoqJQh4moyou\"\n",
    "access_secret = \"zpEe1k4HLWLCY8EIY6pDltde2niMLPfjgt3NEq7TMOLMQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b68d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key=\"t6nkbhDcmFMc7aHFLi70TX0k7\", consumer_secret=\"E2fHiqfgx2BAba2tbwKOSnvvIsPZatHMgqujkbEgCfTgvcjc7d\")\n",
    "auth.set_access_token(key = \"1469208266198732803-REOnVL3cmm7hBcvfPTAoqJQh4moyou\" , secret = \"zpEe1k4HLWLCY8EIY6pDltde2niMLPfjgt3NEq7TMOLMQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6292870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAPI():\n",
    "    API = tweepy.API(auth)\n",
    "\n",
    "    return API\n",
    "\n",
    "\n",
    "def searchTweets(query):\n",
    "    API = getAPI()\n",
    "\n",
    "    tweets = API.search_tweets(q = query, count=100000)\n",
    "\n",
    "    text = []\n",
    "    for tweet in tweets:\n",
    "        text.append(tweet.text)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "   \n",
    "    if not tweets is None and len(tweets) > 0:\n",
    "        for tweet in tweets:\n",
    "            obj = {}\n",
    "            obj['id'] = tweet.id\n",
    "            obj['text'] = tweet.text\n",
    "            results.append(obj) \n",
    "\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    only_text = []\n",
    "    for tweet in text:\n",
    "        if tweet not in only_text:\n",
    "            only_text.append(tweet)\n",
    "\n",
    "\n",
    "    return only_text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8370508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "ashoka_tweets = searchTweets(\"#ashokauniversity\")\n",
    "ashoka_tweets_1 = searchTweets(\"ashoka university\")\n",
    "for x in range(len(ashoka_tweets_1)):\n",
    "    ashoka_tweets.append(ashoka_tweets_1[x])\n",
    "    print(x)\n",
    "print(len(ashoka_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c306f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@rahuleaswar ashokauniversity is hindumisic spreading hatred against hindus the journey of internet startup bigwig @sbikh  @businesstoday httpstcohhjjng13se\n",
      "\n",
      "internet growth… httpstco30bbexx0d7 i think priority is to vaccinate with 1 amp 2 doses as large a population as possible we get to levels of 8090 of… httpstcoqfd2p10vxr i think booster dose is really a priority for people who have been vaccinated early on like health workers its i… httpstcohnytxlwkpy rt @ashokauniv @ashokauniv invites you to a webinar on sarscov2 omicron variant  ask the experts by prof shahid jameel and prof ga… rt @deepikaopines pratap bhanu mehtas exit from ashoka university was an attack on academic freedom for the same progressive academician… rt @byrakeshsimha adi shankara was a devious brahmin with a twisted intellect brahmins become holy after drinking urine of cows th… rt @ukta2001 @byrakeshsimha its not only been taught in ashoka university according to the new syllabus this book is being taught all… rt @viren56002 @byrakeshsimha this ashoka university is another jnu breeding commies hope @hmoindia will act before the dirt reaches the…\n",
      "[['ashokauniversity', 'is', 'hindumisic', 'spreading', 'hatred', 'against', 'hindus'], ['the', 'journey', 'of', 'internet', 'bigwig', 'internet', 'growth…'], ['i', 'think', 'priority', 'is', 'to', 'vaccinate', 'with', 'amp', 'doses', 'as', 'large', 'a', 'population', 'as', 'possible', 'we', 'get', 'to', 'levels', 'of', 'of…'], ['i', 'think', 'booster', 'dose', 'is', 'really', 'a', 'priority', 'for', 'people', 'who', 'have', 'been', 'vaccinated', 'early', 'on', 'like', 'health', 'workers', 'its', 'i…'], ['invites', 'you', 'to', 'a', 'webinar', 'on', 'sarscov2', 'omicron', 'variant', 'ask', 'the', 'by', 'prof', 'shahid', 'jameel', 'and', 'prof', 'ga…'], ['pratap', 'bhanu', 'mehtas', 'exit', 'from', 'ashoka', 'university', 'was', 'an', 'attack', 'on', 'academic', 'freedom', 'for', 'the', 'same', 'progressive', 'academician…'], ['adi', 'shankara', 'was', 'a', 'devious', 'brahmin', 'with', 'a', 'twisted', 'intellect', 'brahmins', 'become', 'holy', 'after', 'drinking', 'urine', 'of', 'cows', 'th…'], ['its', 'not', 'only', 'been', 'taught', 'in', 'ashoka', 'university', 'according', 'to', 'the', 'new', 'syllabus', 'this', 'book', 'is', 'being', 'taught', 'all…'], ['this', 'ashoka', 'university', 'is', 'another', 'jnu', 'breeding', 'commies', 'hope', 'will', 'act', 'before', 'the', 'reaches', 'the…']]\n"
     ]
    }
   ],
   "source": [
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
    "\n",
    "# get rid of punctuation\n",
    "all_tweets = 'separator'.join(ashoka_tweets)\n",
    "all_tweets = all_tweets.lower()\n",
    "all_text = ''.join([c for c in all_tweets if c not in punctuation])\n",
    "\n",
    "# split by new lines and spaces\n",
    "tweets_split = all_text.split('separator')\n",
    "all_text = ' '.join(tweets_split)\n",
    "\n",
    "print(all_text)\n",
    "\n",
    "# create a list of words\n",
    "words = all_text.split()\n",
    "\n",
    "# get rid of web address, twitter id, and digit\n",
    "new_tweets = []\n",
    "for tweet in tweets_split:\n",
    "    tweet = tweet.split()\n",
    "    new_text = []\n",
    "    for word in tweet:\n",
    "        if (word[0] != '@') & ('http' not in word) & (~word.isdigit() & ('rt' not in word)):\n",
    "            new_text.append(word)\n",
    "    new_tweets.append(new_text)\n",
    "\n",
    "print(new_tweets)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b30c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ashokauniversity is hindumisic spreading hatred against hindus', '1'], ['the journey of internet bigwig internet growth…', '1'], ['i think priority is to vaccinate with amp doses as large a population as possible we get to levels of of…', '1'], ['i think booster dose is really a priority for people who have been vaccinated early on like health workers its i…', '1'], ['invites you to a webinar on sarscov2 omicron variant ask the by prof shahid jameel and prof ga…', '1'], ['pratap bhanu mehtas exit from ashoka university was an attack on academic freedom for the same progressive academician…', '1'], ['adi shankara was a devious brahmin with a twisted intellect brahmins become holy after drinking urine of cows th…', '0'], ['its not only been taught in ashoka university according to the new syllabus this book is being taught all…', '1'], ['this ashoka university is another jnu breeding commies hope will act before the reaches the…', '1']]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "tweet_sentences = []\n",
    "for tweet in new_tweets:\n",
    "    sentence = \" \".join(tweet)\n",
    "    tweet_sentences.append(sentence)\n",
    "\n",
    "#print(tweet_sentences)    \n",
    "\n",
    "\n",
    "\n",
    "sentiment_objects = [ ]\n",
    "for tweet in tweet_sentences:\n",
    "    sentiment_objects.append(TextBlob(tweet))\n",
    "\n",
    "\n",
    "#polarity_tweets = []\n",
    "#polarity_tweet = []\n",
    "category_tweet = []\n",
    "category_tweets = []\n",
    "\n",
    "#for i in range(len(tweet_sentences)):\n",
    "    #polarity_tweet = [sentiment_objects[i].polarity, sentiment_objects[i]]\n",
    "    #polarity_tweets.append(polarity_tweet)\n",
    "\n",
    "for i in range(len(tweet_sentences)):\n",
    "    if sentiment_objects[i].polarity >= 0 :\n",
    "        category_tweet = [tweet_sentences[i],'1']\n",
    "\n",
    "    elif sentiment_objects[i].polarity < 0 :\n",
    "        category_tweet = [tweet_sentences[i], '0']    \n",
    "\n",
    "    \n",
    "\n",
    "    category_tweets.append(category_tweet)\n",
    "'''\n",
    "for i in range(len(tweet_sentences)):\n",
    "    category_tweet = [tweet_sentences[i], \"0\"]\n",
    "    category_tweets.append(category_tweet)\n",
    "\n",
    "'''\n",
    "print(category_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "953d4a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweets polarity\n",
      "0  ashokauniversity is hindumisic spreading hatre...        1\n",
      "1    the journey of internet bigwig internet growth…        1\n",
      "2  i think priority is to vaccinate with amp dose...        1\n",
      "3  i think booster dose is really a priority for ...        1\n",
      "4  invites you to a webinar on sarscov2 omicron v...        1\n",
      "5  pratap bhanu mehtas exit from ashoka universit...        1\n",
      "6  adi shankara was a devious brahmin with a twis...        0\n",
      "7  its not only been taught in ashoka university ...        1\n",
      "8  this ashoka university is another jnu breeding...        1\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "my_array = np.array(category_tweets)\n",
    "data = pd.DataFrame(my_array, columns = ['tweets', 'polarity'])\n",
    "\n",
    "\n",
    "\n",
    "data['tweets'] = data['tweets'].str.strip().str.lower()\n",
    "\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd3c82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4af4a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "x = data['tweets']\n",
    "y = data['polarity']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc52585b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vectorize text reviews to numbers\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "x = vec.fit_transform(x).toarray()\n",
    "x_test = vec.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11bd4009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a53af406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d47d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a44b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
